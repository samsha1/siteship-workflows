name: Deploy Airflow DAGs

on:
  push:
    branches: [main]
    tags: ['v*']
  workflow_dispatch:  # Allow manual triggers

jobs:
  check-changes:
    runs-on: ubuntu-latest
    outputs:
      docker-build: ${{ steps.changes.outputs.docker }}
      dags-only: ${{ steps.changes.outputs.dags }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Needed for git diff to work properly
      
      - name: Check for relevant changes
        id: changes
        uses: dorny/paths-filter@v2
        with:
          filters: |
            docker:
              - 'Dockerfile'
              - 'pyproject.toml'
              - 'poetry.lock'
              - 'requirements*.txt'
              - 'docker-compose*.yml'
              - '.github/workflows/deploy.yml'
              - '.version'
            dags:
              - 'dags/**'
              - 'plugins/**'

  build-docker:
    needs: check-changes
    if: needs.check-changes.outputs.docker-build == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy-dags:
    needs: check-changes
    if: always() && (needs.check-changes.outputs.dags-only == 'true' || needs.check-changes.outputs.docker-build == 'true')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python for rsync
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # - name: Install rsync
      #   run: |
      #     sudo apt-get update
      #     sudo apt-get install -y rsync

      - name: Deploy DAGs via rsync
        uses: burnett01/rsync-deployments@7.0.1
        with:
          switches: -avz --delete
          path: dags/
          remote_path: /opt/app/dags/
          remote_host: ${{ secrets.ELESTIO_HOST }}
          remote_user: ${{ secrets.ELESTIO_USER }}
          remote_key: ${{ secrets.ELESTIO_SSH_KEY }}

      # - name: Deploy plugins via rsync
      #   uses: burnett01/rsync-deployments@7.0.1
      #   with:
      #     switches: -avz --delete
      #     path: plugins/
      #     remote_path: /opt/app/plugins/
      #     remote_host: ${{ secrets.ELESTIO_HOST }}
      #     remote_user: ${{ secrets.ELESTIO_USER }}
      #     remote_key: ${{ secrets.ELESTIO_SSH_KEY }}

      - name: Wait for file system sync
        run: sleep 5

      - name: Update Docker image if built
        if: needs.check-changes.outputs.docker-build == 'true'
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: ${{ secrets.ELESTIO_HOST }}
          username: ${{ secrets.ELESTIO_USER }}
          key: ${{ secrets.ELESTIO_SSH_KEY }}
          script: |
            echo "Updating Docker image to latest version..."
            cd /opt/app
            docker compose pull
            docker compose up -d

      - name: Clear serialized DAGs and restart services
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: ${{ secrets.ELESTIO_HOST }}
          username: ${{ secrets.ELESTIO_USER }}
          key: ${{ secrets.ELESTIO_SSH_KEY }}
          script: |
            echo "Clearing serialized DAG cache to prevent race conditions..."
            cd /opt/app
            
            # Clear serialized DAGs table (safe operation, DAGs will be reparsed)
            docker compose exec -T postgres psql -U airflow -d airflow -c "TRUNCATE TABLE serialized_dag CASCADE;" || echo "Warning: Could not clear serialized_dag table"
            
            echo "Restarting Airflow core services..."
            # Stop services first for clean restart
            docker compose stop airflow-scheduler airflow-dag-processor
            
            # Wait to ensure clean shutdown
            sleep 3
            
            # Start services
            docker compose start airflow-scheduler airflow-dag-processor
            
            # Wait for services to initialize
            echo "Waiting for services to initialize..."
            sleep 15
            
            echo "Service status:"
            docker compose ps
            
            # Verify DAG processor is running
            if docker compose ps airflow-dag-processor | grep -q "Up"; then
              echo "✅ DAG processor is running"
            else
              echo "⚠️ Warning: DAG processor may not be healthy yet"
            fi
            
            if docker compose ps airflow-scheduler | grep -q "Up"; then
              echo "✅ Scheduler is running"
            else
              echo "⚠️ Warning: Scheduler may not be healthy yet"
            fi

      - name: Trigger DAG reserialization
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: ${{ secrets.ELESTIO_HOST }}
          username: ${{ secrets.ELESTIO_USER }}
          key: ${{ secrets.ELESTIO_SSH_KEY }}
          script: |
            echo "Triggering DAG reserialization..."
            cd /opt/app
            
            # Trigger DAG reparse (ignore errors if command not available in your Airflow version)
            docker compose exec -T airflow-scheduler airflow dags reserialize || echo "Note: Manual reserialize not available, DAGs will be parsed automatically"
            
            echo "✅ DAGs deployed successfully!"
            echo "DAGs will be available in Airflow UI within 30-60 seconds."